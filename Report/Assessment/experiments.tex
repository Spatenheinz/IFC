% We have conducted a smaller variety of tests. The tests includes both some testing of properties thorugh QuickCheck along with some examples program.

As mentioned, we have conducted a variety of tests to assess the implementation, consisting of both automatic tests and blackbox tests.
To thouroughly test our implementation, the tests follow this testing strategy:
\begin{itemize}
	\item The \textit{Parser} is tested using a blackbox approach, which should cover all aspects of the grammar presented in \cref{table:grammar}.
  Furthermore, we have a QuickCheck test suite for property based tests, which can generate ASTs. This is used to test the \textit{Parser} by generating an AST, and then comparing the result of parsing the pretty printed AST with the actual AST.
	\item We have a test suite using property based testing to test the semantics of the \textit{While} language, which compares the result of running the \textit{Interpreter} on two semantically equivalent generated program constructs.
	\item We attempt to use property based testing to compare interpretation of generated programs with the result of using our VC-generator coupled with \textit{Z3} on the same program.
  \item We use QuickCheck to generate random input for our example programs, which we use to run the programs and compare with the result of running the same computation in Haskell. This is to assert that the example programs does indeed do as we expect them to, telling us whether they should be provable or not.
	\item We test that a provable verification condition also results in a correct dynamic evaluation.
  \item To support the automated tests, we have done some analysis of a selection of programs and compared them to equivalent \textit{Why3} programs.
\end{itemize}

% The examples can be found in the \verb\examples\ folder. Of these some works correctly and some intentionally dont. In the table below, each program can be seen along with a short description on how and why they are included.
A substantial part of the test suites and the experimentation is based on example programs, which can be found in \cref{sec:exampleprogs}.
Some of the examples are working programs, and some are designed to fail.
\cref{table:testprograms} presents the programs (leftmost column), a short description of what they do (middle column), and the results of running them through the \textit{Interpreter} and \textit{VC generator} (rightmost column).
% The leftmost column lists the name of the example programs, the middle column describes the functionality of the program, and the roghtmost column states how both the \textit{Interpreter} and \textit{VC generator} behaves with the program as input.
We will analyse the table more thoroughly in \cref{sec:examples}.

\begin{table}
\input{Assessment/testprograms}
\caption{Overview of example programs}
\label{table:testprograms}
\end{table}

In \crefrange{sec:blackbox}{sec:examples} we present the testing strategy more thoroughly.
First we present the strategy of our blackbox \textit{Parser} tests. 
Next we present our approach to generating automatic tests with property based testing. 
Finally we go into details with the example programs, and how they are designed to test the functionality of the implementation.

\subsubsection{Blackbox testing}\label{sec:blackbox}
\input{Assessment/blackbox}

\subsubsection{Quickchecking instances}\label{sec:qc}
\input{Assessment/qc}

\subsubsection{Dynamic execution compared to static proofs}\label{sec:examples}
\input{Assessment/dynvstat}

